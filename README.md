# Abstract

The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion) [3]. So far they’ve built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content) [3]. We have constructed 4 models that allow for toxic comment classification. We followed the approach of neural network and machine learning to classify comments into their appropriate labels and also predict the labels for new/unused comments. Our models follow four different approaches, which include the use of simple random neural network, then neural network with word embeddings, densely connected network with Recurrent Neural Network and lastly densely connected network with LSTM(Long Short Term Memory). We were able to achieve high level of accuracy with fourth approach which was the densely connected neural network with LSTM.
